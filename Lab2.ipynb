{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2\n",
    "\n",
    "- Brando Reyes\n",
    "- Juan Pablo Solis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Preguntas Teoricas\n",
    "\n",
    "1. ¿Por qué el modelo de Naive Bayes se le considera \"naive\"?\n",
    "    - Este modelo se considera \"Naive\" debido a que asume que todas las características son independientes entre sí, lo cual rara vez es cierto en problemas del mundo real\n",
    "2. Explique la formulación matemática que se busca optimizar en Support Vector Machine, además responda ¿cómo funciona el truco del Kernel para este modelo?\n",
    "3. Investigue sobre Random Forest y responda:\n",
    "    -  ¿Qué tipo de ensemble learning es este modelo?\n",
    "        - Random Forest es un modelo de bagging el cual combina múltiples modelos que se entrenan de manera independiente utilizando diferentes subconjuntos de datos, y luego promedia o vota para obtener la predicción final.\n",
    "    - ¿Cuál es la idea general detrás de Random Forest?\n",
    "        - La idea general de Random Forest es combinar múltiples árboles de decisión para mejorar la precisión y reducir el riesgo de sobreajuste. \n",
    "    - ¿Por qué se busca baja correlación entre los árboles de Random Forest?\n",
    "        - La baja correlación entre los árboles es clave para el éxito de Random Forest porque aumenta su capacidad de generalización. Si los árboles son altamente correlacionados, cometerán los mismos errores, lo que limitaría la mejora obtenida al combinarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Lectura y limpieza de archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  etiqueta                                            mensaje\n",
      "0      ham  go until jurong point, crazy.. available only ...\n",
      "1      ham                      ok lar... joking wif u oni...\n",
      "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      ham  u dun say so early hor... u c already then say...\n",
      "4      ham  nah i don't think he goes to usf, he lives aro...\n",
      "\n",
      "Distribución de clases:\n",
      "etiqueta\n",
      "ham     4818\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo y cargarlo en un DataFrame\n",
    "def cargar_datos(ruta_archivo):\n",
    "    mensajes = []\n",
    "    etiquetas = []\n",
    "    \n",
    "    with open(ruta_archivo, 'r', encoding='utf-8') as archivo:\n",
    "        for linea in archivo:\n",
    "            if \"\\t\" in linea:\n",
    "                etiqueta, mensaje = linea.strip().split(\"\\t\", 1)\n",
    "                etiquetas.append(etiqueta.lower())\n",
    "                mensajes.append(mensaje.lower())  # Convertir a minúsculas para uniformidad\n",
    "    \n",
    "    return pd.DataFrame({'etiqueta': etiquetas, 'mensaje': mensajes})\n",
    "\n",
    "\n",
    "# Procesar los datos\n",
    "ruta_archivo = 'entrenamiento.txt'  # Cambiar por la ruta correcta del archivo\n",
    "df = cargar_datos(ruta_archivo)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Verificar la distribución de clases\n",
    "print(\"\\nDistribución de clases:\")\n",
    "print(df[\"etiqueta\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      etiqueta                                            mensaje\n",
       "0         ham  go until jurong point, crazy.. available only ...\n",
       "1         ham                      ok lar... joking wif u oni...\n",
       "2        spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3         ham  u dun say so early hor... u c already then say...\n",
       "4         ham  nah i don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5560     spam  this is the 2nd time we have tried 2 contact u...\n",
       "5561      ham               will ü b going to esplanade fr home?\n",
       "5562      ham  pity, * was in mood for that. so...any other s...\n",
       "5563      ham  the guy did some bitching but i acted like i'd...\n",
       "5564      ham                         rofl. its true to its name\n",
       "\n",
       "[5565 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  etiqueta                                            mensaje\n",
      "0      ham  go until jurong point crazy available only in ...\n",
      "1      ham                            ok lar joking wif u oni\n",
      "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      ham        u dun say so early hor u c already then say\n",
      "4      ham  nah i dont think he goes to usf he lives aroun...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Función para limpiar el texto\n",
    "def limpiar_mensaje(mensaje):\n",
    "\n",
    "    # Eliminar caracteres especiales excepto letras, números y espacios\n",
    "    mensaje = re.sub(r\"[^a-zA-Z0-9\\s]\", '', mensaje)\n",
    "    # Quitar espacios adicionales\n",
    "    mensaje = re.sub(r'\\s+', ' ', mensaje).strip()\n",
    "    # Convertir a minúsculas\n",
    "    return mensaje.lower()\n",
    "\n",
    "#Aplicar la limpieza al DataFrame\n",
    "df['mensaje'] = df['mensaje'].apply(limpiar_mensaje)\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (4452, 2)\n",
      "Tamaño del conjunto de prueba: (1113, 2)\n",
      "\n",
      "Distribución en el conjunto de entrenamiento:\n",
      "etiqueta\n",
      "ham     0.865678\n",
      "spam    0.134322\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución en el conjunto de prueba:\n",
      "etiqueta\n",
      "ham     0.866128\n",
      "spam    0.133872\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['etiqueta'])\n",
    "\n",
    "# Verificar las formas de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", train_df.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", test_df.shape)\n",
    "\n",
    "# Opcional: Verificar la distribución de clases en ambos conjuntos\n",
    "print(\"\\nDistribución en el conjunto de entrenamiento:\")\n",
    "print(train_df['etiqueta'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución en el conjunto de prueba:\")\n",
    "print(test_df['etiqueta'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 8353\n",
      "Precisión del modelo: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Función para entrenar el modelo basado en Bayes con Laplace Smoothing \n",
    "def entrenar_bayes(mensajes, etiquetas, alpha=1.0):\n",
    "    # Inicializar contadores\n",
    "    total_mensajes = len(mensajes)\n",
    "    total_por_categoria = {}\n",
    "    palabras_por_categoria = {}\n",
    "    total_palabras_por_categoria = {}\n",
    "    vocabulario = set()\n",
    "    \n",
    "    # Procesar cada mensaje\n",
    "    for i in range(len(mensajes)):\n",
    "        etiqueta = etiquetas[i]\n",
    "        mensaje = limpiar_mensaje(mensajes[i])  # Llamar a la función de limpieza\n",
    "        palabras = mensaje.split()\n",
    "        \n",
    "        # Inicializar estructuras para la categoría si no existen\n",
    "        if etiqueta not in total_por_categoria:\n",
    "            total_por_categoria[etiqueta] = 0\n",
    "            palabras_por_categoria[etiqueta] = {}\n",
    "            total_palabras_por_categoria[etiqueta] = 0\n",
    "        \n",
    "        # Actualizar contadores\n",
    "        total_por_categoria[etiqueta] += 1\n",
    "        total_palabras_por_categoria[etiqueta] += len(palabras)\n",
    "        \n",
    "        for palabra in palabras:\n",
    "            vocabulario.add(palabra)\n",
    "            if palabra not in palabras_por_categoria[etiqueta]:\n",
    "                palabras_por_categoria[etiqueta][palabra] = 0\n",
    "            palabras_por_categoria[etiqueta][palabra] += 1\n",
    "    \n",
    "    # Calcular probabilidades con Laplace Smoothing\n",
    "    tamaño_vocabulario = len(vocabulario)\n",
    "    probabilidad_categoria = {cat: total_por_categoria[cat] / total_mensajes for cat in total_por_categoria}\n",
    "    probabilidad_palabra_dado_categoria = {}\n",
    "    \n",
    "    for categoria in palabras_por_categoria:\n",
    "        probabilidad_palabra_dado_categoria[categoria] = {}\n",
    "        for palabra in vocabulario:\n",
    "            conteo_palabra = palabras_por_categoria[categoria].get(palabra, 0)\n",
    "            probabilidad_palabra_dado_categoria[categoria][palabra] = (conteo_palabra + alpha) / (total_palabras_por_categoria[categoria] + alpha * tamaño_vocabulario)\n",
    "    \n",
    "    return probabilidad_categoria, probabilidad_palabra_dado_categoria, tamaño_vocabulario, vocabulario\n",
    "\n",
    "# Función para predecir la categoría de un mensaje\n",
    "def predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=1.0):\n",
    "    mensaje = limpiar_mensaje(mensaje)  # Llamar a la función de limpieza antes de predecir\n",
    "    palabras = mensaje.split()\n",
    "    probabilidades = {}\n",
    "    \n",
    "    for categoria in prob_categoria:\n",
    "        # Iniciar con la probabilidad de la categoría\n",
    "        probabilidad = prob_categoria[categoria]\n",
    "        \n",
    "        # Multiplicar las probabilidades de las palabras\n",
    "        for palabra in palabras:\n",
    "            if palabra in prob_palabra_categoria[categoria]:\n",
    "                probabilidad *= prob_palabra_categoria[categoria][palabra]\n",
    "            else:\n",
    "                # Manejar palabras desconocidas con Laplace Smoothing\n",
    "                probabilidad *= alpha / (tamaño_vocabulario + alpha)\n",
    "        \n",
    "        probabilidades[categoria] = probabilidad\n",
    "    \n",
    "    # Devolver la categoría con mayor probabilidad\n",
    "    return max(probabilidades, key=probabilidades.get)\n",
    "\n",
    "# Entrenar el modelo usando el conjunto de entrenamiento\n",
    "X_train = train_df['mensaje'].tolist()  # Convertir a lista si es necesario\n",
    "y_train = train_df['etiqueta'].tolist()\n",
    "prob_categoria, prob_palabra_categoria, tamaño_vocabulario, vocabulario = entrenar_bayes(X_train, y_train, alpha=0.5)\n",
    "\n",
    "# Imprimir estadísticas del modelo entrenado\n",
    "print(\"Tamaño del vocabulario:\", tamaño_vocabulario)\n",
    "\n",
    "# Probar el modelo con el conjunto de prueba\n",
    "X_test = test_df['mensaje'].tolist()\n",
    "y_test = test_df['etiqueta'].tolist()\n",
    "\n",
    "correctos = 0\n",
    "for i in range(len(X_test)):\n",
    "    mensaje = X_test[i]\n",
    "    etiqueta_real = y_test[i]\n",
    "    etiqueta_predicha = predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=0.5)\n",
    "    \n",
    "    if etiqueta_predicha == etiqueta_real:\n",
    "        correctos += 1\n",
    "\n",
    "# Calcular la precisión\n",
    "precision = correctos / len(X_test)\n",
    "print(f\"Precisión del modelo: {precision:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba Con metrica Recall\n",
    "\n",
    "- Creemos que recall es una metrica adecuada debido a que permite minimizar los falsos negativos. En este caso al tener spam como una clase minoritaria  queremos asegurarnos de que el modelo pueda identificar correctamente la mayor cantidad de mensajes spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entrenamiento manual  ===\n",
      "\n",
      "=== Evaluación en conjunto de entrenamiento ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.975\n",
      "- Recall para ham: 0.997\n",
      "- Recall promedio: 0.986\n",
      "\n",
      "=== Evaluación en conjunto de prueba ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.886\n",
      "- Recall para ham: 0.995\n",
      "- Recall promedio: 0.940\n"
     ]
    }
   ],
   "source": [
    "# Función para calcular el Recall por clase\n",
    "def calcular_recall(y_real, y_pred, clase_objetivo):\n",
    "    verdaderos_positivos = 0\n",
    "    falsos_negativos = 0\n",
    "\n",
    "    for i in range(len(y_real)):\n",
    "        if y_real[i] == clase_objetivo:\n",
    "            if y_pred[i] == clase_objetivo:\n",
    "                verdaderos_positivos += 1\n",
    "            else:\n",
    "                falsos_negativos += 1\n",
    "    \n",
    "    # Recall = Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)\n",
    "    if (verdaderos_positivos + falsos_negativos) == 0:\n",
    "        return 0  # Evitar división por cero\n",
    "    return verdaderos_positivos / (verdaderos_positivos + falsos_negativos)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "y_train_pred = [predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=0.5) for mensaje in X_train]\n",
    "recall_train_spam = calcular_recall(y_train, y_train_pred, clase_objetivo=\"spam\")\n",
    "recall_train_ham = calcular_recall(y_train, y_train_pred, clase_objetivo=\"ham\")\n",
    "recall_train_promedio = (recall_train_spam + recall_train_ham) / 2\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = [predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=0.5) for mensaje in X_test]\n",
    "recall_test_spam = calcular_recall(y_test, y_test_pred, clase_objetivo=\"spam\")\n",
    "recall_test_ham = calcular_recall(y_test, y_test_pred, clase_objetivo=\"ham\")\n",
    "recall_test_promedio = (recall_test_spam + recall_test_ham) / 2\n",
    "\n",
    "# Presentar métricas de desempeño con el formato requerido\n",
    "print(\"=== Entrenamiento manual  ===\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de entrenamiento ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_train_spam:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_train_ham:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_train_promedio:.3f}\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de prueba ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_test_spam:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_test_ham:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_test_promedio:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.3 Mensajes futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Clasificación interactiva de mensajes ===\n",
      "Ingrese un mensaje para clasificarlo. Escriba 'z' para salir.\n",
      "\n",
      "\n",
      "--- Resultados de clasificación ---\n",
      "Mensaje ingresado: \"red car\"\n",
      "Probabilidad de SPAM: 0.014\n",
      "Probabilidad de HAM: 0.986\n",
      "Clasificación: HAM\n",
      "\n",
      "\n",
      "--- Resultados de clasificación ---\n",
      "Mensaje ingresado: \"membership\"\n",
      "Probabilidad de SPAM: 0.327\n",
      "Probabilidad de HAM: 0.673\n",
      "Clasificación: HAM\n",
      "\n",
      "Saliendo del clasificador...\n"
     ]
    }
   ],
   "source": [
    "# Bucle para entrada de mensajes en consola hasta que el usuario escriba \"z\"\n",
    "print(\"\\n=== Clasificación interactiva de mensajes ===\")\n",
    "print(\"Ingrese un mensaje para clasificarlo. Escriba 'z' para salir.\\n\")\n",
    "\n",
    "while True:\n",
    "    mensaje_usuario = input(\"Mensaje: \").strip()\n",
    "    \n",
    "    if mensaje_usuario.lower() == \"z\":\n",
    "        print(\"Saliendo del clasificador...\")\n",
    "        break  # Detener la ejecución cuando el usuario escriba 'z'\n",
    "    \n",
    "    palabras = mensaje_usuario.split()\n",
    "    probabilidades = {}\n",
    "\n",
    "    # Calcular las probabilidades de spam y ham\n",
    "    for categoria in prob_categoria:\n",
    "        probabilidad = prob_categoria[categoria]  # P(Categoria)\n",
    "        \n",
    "        for palabra in palabras:\n",
    "            if palabra in prob_palabra_categoria[categoria]:\n",
    "                probabilidad *= prob_palabra_categoria[categoria][palabra]\n",
    "            else:\n",
    "                # Manejar palabras desconocidas con Laplace Smoothing\n",
    "                probabilidad *= 0.5 / (tamaño_vocabulario + 0.5)\n",
    "        \n",
    "        probabilidades[categoria] = probabilidad\n",
    "\n",
    "    # Normalizar las probabilidades para obtener una distribución entre 0 y 1\n",
    "    suma_probabilidades = sum(probabilidades.values())\n",
    "    if suma_probabilidades > 0:\n",
    "        for categoria in probabilidades:\n",
    "            probabilidades[categoria] /= suma_probabilidades\n",
    "\n",
    "    # Determinar la categoría con mayor probabilidad\n",
    "    categoria_predicha = max(probabilidades, key=probabilidades.get)\n",
    "\n",
    "    # Mostrar resultados en consola\n",
    "    print(\"\\n--- Resultados de clasificación ---\")\n",
    "    print(f\"Mensaje ingresado: \\\"{mensaje_usuario}\\\"\")\n",
    "    print(f\"Probabilidad de SPAM: {probabilidades['spam']:.3f}\")\n",
    "    print(f\"Probabilidad de HAM: {probabilidades['ham']:.3f}\")\n",
    "    print(f\"Clasificación: {categoria_predicha.upper()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Comparacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluación con Naïve Bayes de sklearn ===\n",
      "\n",
      "=== Evaluación en conjunto de entrenamiento ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.977\n",
      "- Recall para ham: 0.997\n",
      "- Recall promedio: 0.987\n",
      "\n",
      "=== Evaluación en conjunto de prueba ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.893\n",
      "- Recall para ham: 0.994\n",
      "- Recall promedio: 0.943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convertir los mensajes en formato numérico usando Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)  # Ajustar y transformar training\n",
    "X_test_vectorized = vectorizer.transform(X_test)  # Solo transformar testing\n",
    "\n",
    "# Entrenar el modelo Naïve Bayes con sklearn\n",
    "modelo_sklearn = MultinomialNB(alpha=0.5)  # Alpha para Laplace Smoothing\n",
    "modelo_sklearn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predicciones en training y testing\n",
    "y_train_pred_sklearn = modelo_sklearn.predict(X_train_vectorized)\n",
    "y_test_pred_sklearn = modelo_sklearn.predict(X_test_vectorized)\n",
    "\n",
    "# Calcular Recall en training y testing\n",
    "recall_train_spam_sklearn = recall_score(y_train, y_train_pred_sklearn, pos_label=\"spam\")\n",
    "recall_train_ham_sklearn = recall_score(y_train, y_train_pred_sklearn, pos_label=\"ham\")\n",
    "recall_train_promedio_sklearn = (recall_train_spam_sklearn + recall_train_ham_sklearn) / 2\n",
    "\n",
    "recall_test_spam_sklearn = recall_score(y_test, y_test_pred_sklearn, pos_label=\"spam\")\n",
    "recall_test_ham_sklearn = recall_score(y_test, y_test_pred_sklearn, pos_label=\"ham\")\n",
    "recall_test_promedio_sklearn = (recall_test_spam_sklearn + recall_test_ham_sklearn) / 2\n",
    "\n",
    "# Presentar métricas de desempeño con el mismo formato que en la implementación manual\n",
    "print(\"=== Evaluación con Naïve Bayes de sklearn ===\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de entrenamiento ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_train_spam_sklearn:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_train_ham_sklearn:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_train_promedio_sklearn:.3f}\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de prueba ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_test_spam_sklearn:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_test_ham_sklearn:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_test_promedio_sklearn:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál implementación lo hizo mejor? ¿Su implementación o la de la librería?\n",
    "    - Ambas pruebas de recall obtuvieron valores similares\n",
    "        - La implementacion con Sklearn tiene mejor Recall para Spam (+0.007), lo que significa que detecta más mensajes spam correctamente.\n",
    "        - Manual tiene mejor Recall para Ham (+0.001), aunque la diferencia es mínima.\n",
    "        - Sklearn tiene mejor Recall Promedio (+0.003), lo que indica un mejor balance en ambas clases.\n",
    "### ¿Por qué cree que se debe esta diferencia?\n",
    "    - La principal diferencia es que sklearn maneja mejor los cálculos numéricos usando logaritmos en lugar de multiplicaciones, evitando errores de precisión y subdesbordamiento. Además, CountVectorizer preprocesa mejor el texto, eliminando ruido y mejorando la representación del mensaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Clasificación de Partidas de League of Legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(etiqueta\n",
       " ham     86.567835\n",
       " spam    13.432165\n",
       " Name: proportion, dtype: float64,\n",
       " etiqueta\n",
       " ham     86.612758\n",
       " spam    13.387242\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['etiqueta'])\n",
    "\n",
    "# Resumen de las divisiones\n",
    "train_summary = train_df['etiqueta'].value_counts(normalize=True) * 100\n",
    "test_summary = test_df['etiqueta'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Mostrar los resúmenes de las divisiones\n",
    "train_summary, test_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      etiqueta                                            mensaje\n",
       " 3223 -0.393908                   no plm i will come da on the way\n",
       " 3289  2.538664  todays voda numbers ending 5226 are selected t...\n",
       " 4399 -0.393908  awesome plan to get here any time after like l...\n",
       " 5410 -0.393908             nope i just forgot will show next week\n",
       " 1536 -0.393908                           midnight at the earliest\n",
       " ...        ...                                                ...\n",
       " 4987 -0.393908  just looked it up and addie goes back monday s...\n",
       " 60   -0.393908  your gonna have to pick up a 1 burger for your...\n",
       " 3670  2.538664  promotion number 8714714 ur awarded a city bre...\n",
       " 1710  2.538664  hard live 121 chat just 60pmin choose your gir...\n",
       " 3777 -0.393908  let me know if you need anything else salad or...\n",
       " \n",
       " [4452 rows x 2 columns],\n",
       "       etiqueta                                            mensaje\n",
       " 3682 -0.393908                           what happen dear tell me\n",
       " 3334 -0.393908                    you will go to walmart ill stay\n",
       " 4311 -0.393908                 are you still playing with gautham\n",
       " 791  -0.393908                        all e best 4 ur driving tmr\n",
       " 1127 -0.393908  so check your errors and if you had difficulti...\n",
       " ...        ...                                                ...\n",
       " 193  -0.393908  it will stop on itself i however suggest she s...\n",
       " 5351 -0.393908  hmm shall i bring a bottle of wine to keep us ...\n",
       " 4300 -0.393908  ha ha had popped down to the loo when you hell...\n",
       " 5453  2.538664  december only had your mobile 11mths you are e...\n",
       " 4805 -0.393908                 i can call in ltgt min if thats ok\n",
       " \n",
       " [1113 rows x 2 columns])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinicio del flujo de trabajo desde la carga del dataset\n",
    "# Asegurarse de que el dataset df esté definido antes de continuar\n",
    "\n",
    "# Simulación de una estructura básica para el dataframe df (puedes reemplazarlo con el real)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Definir un dataset de ejemplo para simular el proceso (sustituir con el dataset real)\n",
    "data = {\n",
    "    'etiqueta': ['ham', 'spam', 'ham', 'spam', 'ham'],\n",
    "    'caracteristica_1': [10, 20, 10, 30, 10],\n",
    "    'caracteristica_2': [1.5, 2.5, 1.5, 3.5, 1.5]\n",
    "}\n",
    "#df = pd.DataFrame(data)\n",
    "df = df\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['etiqueta'])\n",
    "\n",
    "# Crear una copia para preprocesamiento\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "# Paso 1: Encoding de la etiqueta (ham/spam -> 0/1)\n",
    "label_encoder = LabelEncoder()\n",
    "train_processed['etiqueta'] = label_encoder.fit_transform(train_processed['etiqueta'])\n",
    "test_processed['etiqueta'] = label_encoder.transform(test_processed['etiqueta'])\n",
    "\n",
    "# Paso 2: Escalar características numéricas\n",
    "numeric_cols = train_processed.select_dtypes(include=['float64', 'int']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_processed[numeric_cols] = scaler.fit_transform(train_processed[numeric_cols])\n",
    "test_processed[numeric_cols] = scaler.transform(test_processed[numeric_cols])\n",
    "\n",
    "# Mostrar los resultados procesados\n",
    "train_processed, test_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       964\n",
      "        spam       0.97      0.87      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1113\n",
      "   macro avg       0.98      0.93      0.95      1113\n",
      "weighted avg       0.98      0.98      0.98      1113\n",
      "\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[960   4]\n",
      " [ 19 130]]\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Supongamos que 'df' ya está definido y limpio\n",
    "# Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['etiqueta'])\n",
    "\n",
    "# Codificar etiquetas (ham/spam -> 0/1)\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['etiqueta'] = label_encoder.fit_transform(train_df['etiqueta'])\n",
    "test_df['etiqueta'] = label_encoder.transform(test_df['etiqueta'])\n",
    "\n",
    "# Vectorizar los mensajes usando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)  # Máximo de 500 palabras más frecuentes\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['mensaje']).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['mensaje']).toarray()\n",
    "\n",
    "# Etiquetas para entrenamiento y prueba\n",
    "y_train = train_df['etiqueta']\n",
    "y_test = test_df['etiqueta']\n",
    "\n",
    "# Entrenar un modelo SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluar el modelo\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, elegimos el **F1-score** como métrica de desempeño principal porque nos permite balancear precisión y recall, lo cual es crucial en problemas como la clasificación de spam, donde el dataset suele estar desbalanceado. Esta métrica armoniza la capacidad del modelo para identificar correctamente los mensajes spam (precisión) y para no dejar mensajes spam sin clasificar (recall). Además, ambos errores tienen implicaciones importantes: los falsos positivos afectan la experiencia del usuario al clasificar mensajes válidos como spam, mientras que los falsos negativos permiten que mensajes no deseados pasen desapercibidos. Con un F1-score promedio del 95%, el modelo demuestra un buen desempeño equilibrado en ambas clases, lo que lo hace adecuado para este tipo de problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.2 - Support Vector Machines: Clasificación de Partidas de League of Legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9879 entries, 0 to 9878\n",
      "Data columns (total 40 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   gameId                        9879 non-null   int64  \n",
      " 1   blueWins                      9879 non-null   int64  \n",
      " 2   blueWardsPlaced               9879 non-null   int64  \n",
      " 3   blueWardsDestroyed            9879 non-null   int64  \n",
      " 4   blueFirstBlood                9879 non-null   int64  \n",
      " 5   blueKills                     9879 non-null   int64  \n",
      " 6   blueDeaths                    9879 non-null   int64  \n",
      " 7   blueAssists                   9879 non-null   int64  \n",
      " 8   blueEliteMonsters             9879 non-null   int64  \n",
      " 9   blueDragons                   9879 non-null   int64  \n",
      " 10  blueHeralds                   9879 non-null   int64  \n",
      " 11  blueTowersDestroyed           9879 non-null   int64  \n",
      " 12  blueTotalGold                 9879 non-null   int64  \n",
      " 13  blueAvgLevel                  9879 non-null   float64\n",
      " 14  blueTotalExperience           9879 non-null   int64  \n",
      " 15  blueTotalMinionsKilled        9879 non-null   int64  \n",
      " 16  blueTotalJungleMinionsKilled  9879 non-null   int64  \n",
      " 17  blueGoldDiff                  9879 non-null   int64  \n",
      " 18  blueExperienceDiff            9879 non-null   int64  \n",
      " 19  blueCSPerMin                  9879 non-null   float64\n",
      " 20  blueGoldPerMin                9879 non-null   float64\n",
      " 21  redWardsPlaced                9879 non-null   int64  \n",
      " 22  redWardsDestroyed             9879 non-null   int64  \n",
      " 23  redFirstBlood                 9879 non-null   int64  \n",
      " 24  redKills                      9879 non-null   int64  \n",
      " 25  redDeaths                     9879 non-null   int64  \n",
      " 26  redAssists                    9879 non-null   int64  \n",
      " 27  redEliteMonsters              9879 non-null   int64  \n",
      " 28  redDragons                    9879 non-null   int64  \n",
      " 29  redHeralds                    9879 non-null   int64  \n",
      " 30  redTowersDestroyed            9879 non-null   int64  \n",
      " 31  redTotalGold                  9879 non-null   int64  \n",
      " 32  redAvgLevel                   9879 non-null   float64\n",
      " 33  redTotalExperience            9879 non-null   int64  \n",
      " 34  redTotalMinionsKilled         9879 non-null   int64  \n",
      " 35  redTotalJungleMinionsKilled   9879 non-null   int64  \n",
      " 36  redGoldDiff                   9879 non-null   int64  \n",
      " 37  redExperienceDiff             9879 non-null   int64  \n",
      " 38  redCSPerMin                   9879 non-null   float64\n",
      " 39  redGoldPerMin                 9879 non-null   float64\n",
      "dtypes: float64(6), int64(34)\n",
      "memory usage: 3.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       gameId  blueWins  blueWardsPlaced  blueWardsDestroyed  blueFirstBlood  \\\n",
       " 0  4519157822         0               28                   2               1   \n",
       " 1  4523371949         0               12                   1               0   \n",
       " 2  4521474530         0               15                   0               0   \n",
       " 3  4524384067         0               43                   1               0   \n",
       " 4  4436033771         0               75                   4               0   \n",
       " \n",
       "    blueKills  blueDeaths  blueAssists  blueEliteMonsters  blueDragons  ...  \\\n",
       " 0          9           6           11                  0            0  ...   \n",
       " 1          5           5            5                  0            0  ...   \n",
       " 2          7          11            4                  1            1  ...   \n",
       " 3          4           5            5                  1            0  ...   \n",
       " 4          6           6            6                  0            0  ...   \n",
       " \n",
       "    redTowersDestroyed  redTotalGold  redAvgLevel  redTotalExperience  \\\n",
       " 0                   0         16567          6.8               17047   \n",
       " 1                   1         17620          6.8               17438   \n",
       " 2                   0         17285          6.8               17254   \n",
       " 3                   0         16478          7.0               17961   \n",
       " 4                   0         17404          7.0               18313   \n",
       " \n",
       "    redTotalMinionsKilled  redTotalJungleMinionsKilled  redGoldDiff  \\\n",
       " 0                    197                           55         -643   \n",
       " 1                    240                           52         2908   \n",
       " 2                    203                           28         1172   \n",
       " 3                    235                           47         1321   \n",
       " 4                    225                           67         1004   \n",
       " \n",
       "    redExperienceDiff  redCSPerMin  redGoldPerMin  \n",
       " 0                  8         19.7         1656.7  \n",
       " 1               1173         24.0         1762.0  \n",
       " 2               1033         20.3         1728.5  \n",
       " 3                  7         23.5         1647.8  \n",
       " 4               -230         22.5         1740.4  \n",
       " \n",
       " [5 rows x 40 columns],\n",
       " None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset proporcionado\n",
    "dataset_path = \"high_diamond_ranked_10min.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Mostrar las primeras filas para verificar la estructura\n",
    "df.head(), df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7903, 2), (988, 2), (988, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar las columnas relevantes (dos para graficar y la variable objetivo)\n",
    "columns_to_use = ['blueGoldPerMin', 'blueCSPerMin', 'blueWins']\n",
    "df_subset = df[columns_to_use]\n",
    "\n",
    "# Dividir el dataset en entrenamiento (80%), validación (10%) y prueba (10%)\n",
    "train_data, temp_data = train_test_split(\n",
    "    df_subset, test_size=0.2, random_state=42, stratify=df_subset['blueWins']\n",
    ")\n",
    "val_data, test_data = train_test_split(\n",
    "    temp_data, test_size=0.5, random_state=42, stratify=temp_data['blueWins']\n",
    ")\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X_train = train_data[['blueGoldPerMin', 'blueCSPerMin']].values\n",
    "y_train = train_data['blueWins'].values\n",
    "X_val = val_data[['blueGoldPerMin', 'blueCSPerMin']].values\n",
    "y_val = val_data['blueWins'].values\n",
    "X_test = test_data[['blueGoldPerMin', 'blueCSPerMin']].values\n",
    "y_test = test_data['blueWins'].values\n",
    "\n",
    "# Verificar las divisiones\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación (SVM desde cero con while): 0.49898785425101216\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Clase SVM básica\n",
    "class SimpleSVM:\n",
    "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
    "        self.learning_rate = learning_rate  # Tasa de aprendizaje\n",
    "        self.lambda_param = lambda_param  # Parámetro de regularización\n",
    "        self.n_iters = n_iters  # Número de iteraciones\n",
    "        self.w = None  # Pesos\n",
    "        self.b = None  # Sesgo\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y_ = np.where(y <= 0, -1, 1)  # Convertir etiquetas 0 a -1\n",
    "        self.w = np.zeros(n_features)  # Inicializar pesos con ceros\n",
    "        self.b = 0  # Inicializar sesgo a 0\n",
    "\n",
    "        # Gradiente descendente usando while\n",
    "        iteration = 0\n",
    "        while iteration < self.n_iters:\n",
    "            idx = 0\n",
    "            while idx < n_samples:\n",
    "                # Condición para verificar si el ejemplo cumple con la regla\n",
    "                condition = y_[idx] * (np.dot(X[idx], self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    # Solo actualizar los pesos por regularización\n",
    "                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    # Actualizar pesos y sesgo\n",
    "                    self.w -= self.learning_rate * (\n",
    "                        2 * self.lambda_param * self.w - np.dot(X[idx], y_[idx])\n",
    "                    )\n",
    "                    self.b -= self.learning_rate * y_[idx]\n",
    "                idx += 1  # Avanzar al siguiente ejemplo\n",
    "            iteration += 1  # Incrementar la iteración\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calcular las predicciones\n",
    "        approx = np.dot(X, self.w) - self.b\n",
    "        return np.sign(approx)\n",
    "\n",
    "# Crear y entrenar el modelo SVM\n",
    "svm = SimpleSVM(learning_rate=0.001, lambda_param=0.01, n_iters=1000)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en el conjunto de validación\n",
    "y_val_pred = svm.predict(X_val)\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = np.mean(y_val == (y_val_pred > 0))\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Accuracy en validación (SVM desde cero con while):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación (SVM con librerías): 0.6933198380566802\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       495\n",
      "           1       0.69      0.69      0.69       493\n",
      "\n",
      "    accuracy                           0.69       988\n",
      "   macro avg       0.69      0.69      0.69       988\n",
      "weighted avg       0.69      0.69      0.69       988\n",
      "\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[345 150]\n",
      " [153 340]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Crear y entrenar el modelo SVM\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción y evaluación\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"Accuracy en validación (SVM con librerías):\", accuracy)\n",
    "\n",
    "# Reporte de clasificación y matriz de confusión\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de **SVM con librerías** fue significativamente mejor que la implementación desde cero. Utilizando Scikit-learn, se logró un **accuracy de 69.33%** en el conjunto de validación, mientras que la implementación desde cero alcanzó únicamente un 49.90%. Esto se debe a que Scikit-learn optimiza el entrenamiento mediante operaciones matriciales y algoritmos eficientes, lo que permite un mejor ajuste de las fronteras de decisión. Además, la versión con librerías ofrece herramientas para ajustar parámetros como el kernel y la regularización, lo que mejora el desempeño del modelo. En contraste, la implementación desde cero, aunque útil para entender los fundamentos del algoritmo, es menos eficiente y no logra capturar las relaciones complejas en los datos.\n",
    "\n",
    "Por otro lado, el tiempo de ejecución fue notablemente menor en la implementación con librerías. La versión desde cero utiliza bucles `while`, lo que aumenta el tiempo de entrenamiento, especialmente con un dataset de tamaño considerable. A pesar de que la implementación manual fomenta el aprendizaje del funcionamiento interno del SVM, para problemas reales y más complejos, el uso de librerías es mucho más práctico y efectivo. En conclusión, Scikit-learn no solo ofrece mejores resultados en términos de precisión, sino que también permite un desarrollo más eficiente y ajustado a las necesidades del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.3 - Comparación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3.3 - Comparación\n",
    "¿Cómo difirieron los grupos creados por ambos modelos?\n",
    "Los grupos creados por el modelo implementado desde cero y el modelo de librerías fueron bastante distintos en calidad. El modelo desde cero obtuvo un accuracy de 49.90%, lo que refleja que no logró ajustar correctamente las fronteras de decisión, provocando grupos poco definidos y clasificando de manera casi aleatoria. En cambio, el modelo con librerías alcanzó un accuracy de 69.33%, mostrando una clara mejora al identificar patrones en los datos y formando grupos más precisos. Esto es resultado de las optimizaciones matemáticas y de los ajustes de hiperparámetros que Scikit-learn realiza de forma eficiente.\n",
    "\n",
    "¿Cuál de los modelos fue más rápido?\n",
    "El modelo con librerías fue mucho más rápido en comparación con el modelo desde cero. Este último tardó 264 segundos, mientras que el modelo con librerías completó su entrenamiento y predicción en solo 8.7 segundos. Esto se debe a que Scikit-learn utiliza cálculos matriciales optimizados, mientras que la implementación desde cero dependió de ciclos while, lo que ralentiza el procesamiento debido a su naturaleza iterativa y menos eficiente.\n",
    "\n",
    "¿Qué modelo usarían?\n",
    "Para resolver problemas reales o trabajar con datasets más complejos, definitivamente usaría el modelo con librerías. Además de ser más rápido, logra mejores resultados de precisión y es más fácil de ajustar a través de la configuración de hiperparámetros como el kernel y la regularización. Aunque implementar un modelo desde cero es una excelente forma de entender el funcionamiento del SVM, no es práctico para aplicaciones en la vida real debido a sus limitaciones de rendimiento y escalabilidad.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
