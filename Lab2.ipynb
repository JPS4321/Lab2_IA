{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2\n",
    "\n",
    "- Brando Reyes\n",
    "- Juan Pablo Solis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Preguntas Teoricas\n",
    "\n",
    "1. ¿Por qué el modelo de Naive Bayes se le considera \"naive\"?\n",
    "    - Este modelo se considera \"Naive\" debido a que asume que todas las características son independientes entre sí, lo cual rara vez es cierto en problemas del mundo real\n",
    "2. Explique la formulación matemática que se busca optimizar en Support Vector Machine, además responda ¿cómo funciona el truco del Kernel para este modelo?\n",
    "3. Investigue sobre Random Forest y responda:\n",
    "    -  ¿Qué tipo de ensemble learning es este modelo?\n",
    "        - Random Forest es un modelo de bagging el cual combina múltiples modelos que se entrenan de manera independiente utilizando diferentes subconjuntos de datos, y luego promedia o vota para obtener la predicción final.\n",
    "    - ¿Cuál es la idea general detrás de Random Forest?\n",
    "        - La idea general de Random Forest es combinar múltiples árboles de decisión para mejorar la precisión y reducir el riesgo de sobreajuste. \n",
    "    - ¿Por qué se busca baja correlación entre los árboles de Random Forest?\n",
    "        - La baja correlación entre los árboles es clave para el éxito de Random Forest porque aumenta su capacidad de generalización. Si los árboles son altamente correlacionados, cometerán los mismos errores, lo que limitaría la mejora obtenida al combinarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Lectura y limpieza de archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  etiqueta                                            mensaje\n",
      "0      ham  go until jurong point, crazy.. available only ...\n",
      "1      ham                      ok lar... joking wif u oni...\n",
      "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      ham  u dun say so early hor... u c already then say...\n",
      "4      ham  nah i don't think he goes to usf, he lives aro...\n",
      "\n",
      "Distribución de clases:\n",
      "etiqueta\n",
      "ham     4818\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo y cargarlo en un DataFrame\n",
    "def cargar_datos(ruta_archivo):\n",
    "    mensajes = []\n",
    "    etiquetas = []\n",
    "    \n",
    "    with open(ruta_archivo, 'r', encoding='utf-8') as archivo:\n",
    "        for linea in archivo:\n",
    "            if \"\\t\" in linea:\n",
    "                etiqueta, mensaje = linea.strip().split(\"\\t\", 1)\n",
    "                etiquetas.append(etiqueta.lower())\n",
    "                mensajes.append(mensaje.lower())  # Convertir a minúsculas para uniformidad\n",
    "    \n",
    "    return pd.DataFrame({'etiqueta': etiquetas, 'mensaje': mensajes})\n",
    "\n",
    "\n",
    "# Procesar los datos\n",
    "ruta_archivo = 'entrenamiento.txt'  # Cambiar por la ruta correcta del archivo\n",
    "df = cargar_datos(ruta_archivo)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Verificar la distribución de clases\n",
    "print(\"\\nDistribución de clases:\")\n",
    "print(df[\"etiqueta\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      etiqueta                                            mensaje\n",
       "0         ham  go until jurong point, crazy.. available only ...\n",
       "1         ham                      ok lar... joking wif u oni...\n",
       "2        spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3         ham  u dun say so early hor... u c already then say...\n",
       "4         ham  nah i don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5560     spam  this is the 2nd time we have tried 2 contact u...\n",
       "5561      ham               will ü b going to esplanade fr home?\n",
       "5562      ham  pity, * was in mood for that. so...any other s...\n",
       "5563      ham  the guy did some bitching but i acted like i'd...\n",
       "5564      ham                         rofl. its true to its name\n",
       "\n",
       "[5565 rows x 2 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  etiqueta                                            mensaje\n",
      "0      ham  go until jurong point crazy available only in ...\n",
      "1      ham                            ok lar joking wif u oni\n",
      "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      ham        u dun say so early hor u c already then say\n",
      "4      ham  nah i dont think he goes to usf he lives aroun...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Función para limpiar el texto\n",
    "def limpiar_mensaje(mensaje):\n",
    "\n",
    "    # Eliminar caracteres especiales excepto letras, números y espacios\n",
    "    mensaje = re.sub(r\"[^a-zA-Z0-9\\s]\", '', mensaje)\n",
    "    # Quitar espacios adicionales\n",
    "    mensaje = re.sub(r'\\s+', ' ', mensaje).strip()\n",
    "    # Convertir a minúsculas\n",
    "    return mensaje.lower()\n",
    "\n",
    "#Aplicar la limpieza al DataFrame\n",
    "df['mensaje'] = df['mensaje'].apply(limpiar_mensaje)\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (4452, 2)\n",
      "Tamaño del conjunto de prueba: (1113, 2)\n",
      "\n",
      "Distribución en el conjunto de entrenamiento:\n",
      "etiqueta\n",
      "ham     0.865678\n",
      "spam    0.134322\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución en el conjunto de prueba:\n",
      "etiqueta\n",
      "ham     0.866128\n",
      "spam    0.133872\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['etiqueta'])\n",
    "\n",
    "# Verificar las formas de los conjuntos\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", train_df.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", test_df.shape)\n",
    "\n",
    "# Opcional: Verificar la distribución de clases en ambos conjuntos\n",
    "print(\"\\nDistribución en el conjunto de entrenamiento:\")\n",
    "print(train_df['etiqueta'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución en el conjunto de prueba:\")\n",
    "print(test_df['etiqueta'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 8353\n",
      "Precisión del modelo: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Función para entrenar el modelo basado en Bayes con Laplace Smoothing \n",
    "def entrenar_bayes(mensajes, etiquetas, alpha=1.0):\n",
    "    # Inicializar contadores\n",
    "    total_mensajes = len(mensajes)\n",
    "    total_por_categoria = {}\n",
    "    palabras_por_categoria = {}\n",
    "    total_palabras_por_categoria = {}\n",
    "    vocabulario = set()\n",
    "    \n",
    "    # Procesar cada mensaje\n",
    "    for i in range(len(mensajes)):\n",
    "        etiqueta = etiquetas[i]\n",
    "        mensaje = limpiar_mensaje(mensajes[i])  # Llamar a la función de limpieza\n",
    "        palabras = mensaje.split()\n",
    "        \n",
    "        # Inicializar estructuras para la categoría si no existen\n",
    "        if etiqueta not in total_por_categoria:\n",
    "            total_por_categoria[etiqueta] = 0\n",
    "            palabras_por_categoria[etiqueta] = {}\n",
    "            total_palabras_por_categoria[etiqueta] = 0\n",
    "        \n",
    "        # Actualizar contadores\n",
    "        total_por_categoria[etiqueta] += 1\n",
    "        total_palabras_por_categoria[etiqueta] += len(palabras)\n",
    "        \n",
    "        for palabra in palabras:\n",
    "            vocabulario.add(palabra)\n",
    "            if palabra not in palabras_por_categoria[etiqueta]:\n",
    "                palabras_por_categoria[etiqueta][palabra] = 0\n",
    "            palabras_por_categoria[etiqueta][palabra] += 1\n",
    "    \n",
    "    # Calcular probabilidades con Laplace Smoothing\n",
    "    tamaño_vocabulario = len(vocabulario)\n",
    "    probabilidad_categoria = {cat: total_por_categoria[cat] / total_mensajes for cat in total_por_categoria}\n",
    "    probabilidad_palabra_dado_categoria = {}\n",
    "    \n",
    "    for categoria in palabras_por_categoria:\n",
    "        probabilidad_palabra_dado_categoria[categoria] = {}\n",
    "        for palabra in vocabulario:\n",
    "            conteo_palabra = palabras_por_categoria[categoria].get(palabra, 0)\n",
    "            probabilidad_palabra_dado_categoria[categoria][palabra] = (conteo_palabra + alpha) / (total_palabras_por_categoria[categoria] + alpha * tamaño_vocabulario)\n",
    "    \n",
    "    return probabilidad_categoria, probabilidad_palabra_dado_categoria, tamaño_vocabulario, vocabulario\n",
    "\n",
    "# Función para predecir la categoría de un mensaje\n",
    "def predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=1.0):\n",
    "    mensaje = limpiar_mensaje(mensaje)  # Llamar a la función de limpieza antes de predecir\n",
    "    palabras = mensaje.split()\n",
    "    probabilidades = {}\n",
    "    \n",
    "    for categoria in prob_categoria:\n",
    "        # Iniciar con la probabilidad de la categoría\n",
    "        probabilidad = prob_categoria[categoria]\n",
    "        \n",
    "        # Multiplicar las probabilidades de las palabras\n",
    "        for palabra in palabras:\n",
    "            if palabra in prob_palabra_categoria[categoria]:\n",
    "                probabilidad *= prob_palabra_categoria[categoria][palabra]\n",
    "            else:\n",
    "                # Manejar palabras desconocidas con Laplace Smoothing\n",
    "                probabilidad *= alpha / (tamaño_vocabulario + alpha)\n",
    "        \n",
    "        probabilidades[categoria] = probabilidad\n",
    "    \n",
    "    # Devolver la categoría con mayor probabilidad\n",
    "    return max(probabilidades, key=probabilidades.get)\n",
    "\n",
    "# Entrenar el modelo usando el conjunto de entrenamiento\n",
    "X_train = train_df['mensaje'].tolist()  # Convertir a lista si es necesario\n",
    "y_train = train_df['etiqueta'].tolist()\n",
    "prob_categoria, prob_palabra_categoria, tamaño_vocabulario, vocabulario = entrenar_bayes(X_train, y_train, alpha=0.5)\n",
    "\n",
    "# Imprimir estadísticas del modelo entrenado\n",
    "print(\"Tamaño del vocabulario:\", tamaño_vocabulario)\n",
    "\n",
    "# Probar el modelo con el conjunto de prueba\n",
    "X_test = test_df['mensaje'].tolist()\n",
    "y_test = test_df['etiqueta'].tolist()\n",
    "\n",
    "correctos = 0\n",
    "for i in range(len(X_test)):\n",
    "    mensaje = X_test[i]\n",
    "    etiqueta_real = y_test[i]\n",
    "    etiqueta_predicha = predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=0.5)\n",
    "    \n",
    "    if etiqueta_predicha == etiqueta_real:\n",
    "        correctos += 1\n",
    "\n",
    "# Calcular la precisión\n",
    "precision = correctos / len(X_test)\n",
    "print(f\"Precisión del modelo: {precision:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba Con metrica Recall\n",
    "\n",
    "- Creemos que recall es una metrica adecuada debido a que permite minimizar los falsos negativos. En este caso al tener spam como una clase minoritaria  queremos asegurarnos de que el modelo pueda identificar correctamente la mayor cantidad de mensajes spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entrenamiento manual  ===\n",
      "\n",
      "=== Evaluación en conjunto de entrenamiento ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.975\n",
      "- Recall para ham: 0.997\n",
      "- Recall promedio: 0.986\n",
      "\n",
      "=== Evaluación en conjunto de prueba ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.886\n",
      "- Recall para ham: 0.995\n",
      "- Recall promedio: 0.940\n"
     ]
    }
   ],
   "source": [
    "# Función para calcular el Recall por clase\n",
    "def calcular_recall(y_real, y_pred, clase_objetivo):\n",
    "    verdaderos_positivos = 0\n",
    "    falsos_negativos = 0\n",
    "\n",
    "    for i in range(len(y_real)):\n",
    "        if y_real[i] == clase_objetivo:\n",
    "            if y_pred[i] == clase_objetivo:\n",
    "                verdaderos_positivos += 1\n",
    "            else:\n",
    "                falsos_negativos += 1\n",
    "    \n",
    "    # Recall = Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)\n",
    "    if (verdaderos_positivos + falsos_negativos) == 0:\n",
    "        return 0  # Evitar división por cero\n",
    "    return verdaderos_positivos / (verdaderos_positivos + falsos_negativos)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de entrenamiento\n",
    "y_train_pred = [predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=0.5) for mensaje in X_train]\n",
    "recall_train_spam = calcular_recall(y_train, y_train_pred, clase_objetivo=\"spam\")\n",
    "recall_train_ham = calcular_recall(y_train, y_train_pred, clase_objetivo=\"ham\")\n",
    "recall_train_promedio = (recall_train_spam + recall_train_ham) / 2\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_test_pred = [predecir_bayes_flexible(mensaje, prob_categoria, prob_palabra_categoria, tamaño_vocabulario, alpha=0.5) for mensaje in X_test]\n",
    "recall_test_spam = calcular_recall(y_test, y_test_pred, clase_objetivo=\"spam\")\n",
    "recall_test_ham = calcular_recall(y_test, y_test_pred, clase_objetivo=\"ham\")\n",
    "recall_test_promedio = (recall_test_spam + recall_test_ham) / 2\n",
    "\n",
    "# Presentar métricas de desempeño con el formato requerido\n",
    "print(\"=== Entrenamiento manual  ===\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de entrenamiento ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_train_spam:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_train_ham:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_train_promedio:.3f}\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de prueba ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_test_spam:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_test_ham:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_test_promedio:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.3 Mensajes futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Clasificación interactiva de mensajes ===\n",
      "Ingrese un mensaje para clasificarlo. Escriba 'z' para salir.\n",
      "\n",
      "\n",
      "--- Resultados de clasificación ---\n",
      "Mensaje ingresado: \"Hello, you have won a brand new car! Just click the following link\"\n",
      "Probabilidad de SPAM: 1.000\n",
      "Probabilidad de HAM: 0.000\n",
      "Clasificación: SPAM\n",
      "\n",
      "\n",
      "--- Resultados de clasificación ---\n",
      "Mensaje ingresado: \"Dave did you finish your homework?\"\n",
      "Probabilidad de SPAM: 0.001\n",
      "Probabilidad de HAM: 0.999\n",
      "Clasificación: HAM\n",
      "\n",
      "\n",
      "--- Resultados de clasificación ---\n",
      "Mensaje ingresado: \"What time is it?\"\n",
      "Probabilidad de SPAM: 0.040\n",
      "Probabilidad de HAM: 0.960\n",
      "Clasificación: HAM\n",
      "\n",
      "Saliendo del clasificador...\n"
     ]
    }
   ],
   "source": [
    "# Bucle para entrada de mensajes en consola hasta que el usuario escriba \"z\"\n",
    "print(\"\\n=== Clasificación interactiva de mensajes ===\")\n",
    "print(\"Ingrese un mensaje para clasificarlo. Escriba 'z' para salir.\\n\")\n",
    "\n",
    "while True:\n",
    "    mensaje_usuario = input(\"Mensaje: \").strip()\n",
    "    \n",
    "    if mensaje_usuario.lower() == \"z\":\n",
    "        print(\"Saliendo del clasificador...\")\n",
    "        break  # Detener la ejecución cuando el usuario escriba 'z'\n",
    "    \n",
    "    palabras = mensaje_usuario.split()\n",
    "    probabilidades = {}\n",
    "\n",
    "    # Calcular las probabilidades de spam y ham\n",
    "    for categoria in prob_categoria:\n",
    "        probabilidad = prob_categoria[categoria]  # P(Categoria)\n",
    "        \n",
    "        for palabra in palabras:\n",
    "            if palabra in prob_palabra_categoria[categoria]:\n",
    "                probabilidad *= prob_palabra_categoria[categoria][palabra]\n",
    "            else:\n",
    "                # Manejar palabras desconocidas con Laplace Smoothing\n",
    "                probabilidad *= 0.5 / (tamaño_vocabulario + 0.5)\n",
    "        \n",
    "        probabilidades[categoria] = probabilidad\n",
    "\n",
    "    # Normalizar las probabilidades para obtener una distribución entre 0 y 1\n",
    "    suma_probabilidades = sum(probabilidades.values())\n",
    "    if suma_probabilidades > 0:\n",
    "        for categoria in probabilidades:\n",
    "            probabilidades[categoria] /= suma_probabilidades\n",
    "\n",
    "    # Determinar la categoría con mayor probabilidad\n",
    "    categoria_predicha = max(probabilidades, key=probabilidades.get)\n",
    "\n",
    "    # Mostrar resultados en consola\n",
    "    print(\"\\n--- Resultados de clasificación ---\")\n",
    "    print(f\"Mensaje ingresado: \\\"{mensaje_usuario}\\\"\")\n",
    "    print(f\"Probabilidad de SPAM: {probabilidades['spam']:.3f}\")\n",
    "    print(f\"Probabilidad de HAM: {probabilidades['ham']:.3f}\")\n",
    "    print(f\"Clasificación: {categoria_predicha.upper()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Comparacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluación con Naïve Bayes de sklearn ===\n",
      "\n",
      "=== Evaluación en conjunto de entrenamiento ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.977\n",
      "- Recall para ham: 0.997\n",
      "- Recall promedio: 0.987\n",
      "\n",
      "=== Evaluación en conjunto de prueba ===\n",
      "\n",
      "Métricas de evaluación:\n",
      "- Recall para spam: 0.893\n",
      "- Recall para ham: 0.994\n",
      "- Recall promedio: 0.943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convertir los mensajes en formato numérico usando Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)  # Ajustar y transformar training\n",
    "X_test_vectorized = vectorizer.transform(X_test)  # Solo transformar testing\n",
    "\n",
    "# Entrenar el modelo Naïve Bayes con sklearn\n",
    "modelo_sklearn = MultinomialNB(alpha=0.5)  # Alpha para Laplace Smoothing\n",
    "modelo_sklearn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predicciones en training y testing\n",
    "y_train_pred_sklearn = modelo_sklearn.predict(X_train_vectorized)\n",
    "y_test_pred_sklearn = modelo_sklearn.predict(X_test_vectorized)\n",
    "\n",
    "# Calcular Recall en training y testing\n",
    "recall_train_spam_sklearn = recall_score(y_train, y_train_pred_sklearn, pos_label=\"spam\")\n",
    "recall_train_ham_sklearn = recall_score(y_train, y_train_pred_sklearn, pos_label=\"ham\")\n",
    "recall_train_promedio_sklearn = (recall_train_spam_sklearn + recall_train_ham_sklearn) / 2\n",
    "\n",
    "recall_test_spam_sklearn = recall_score(y_test, y_test_pred_sklearn, pos_label=\"spam\")\n",
    "recall_test_ham_sklearn = recall_score(y_test, y_test_pred_sklearn, pos_label=\"ham\")\n",
    "recall_test_promedio_sklearn = (recall_test_spam_sklearn + recall_test_ham_sklearn) / 2\n",
    "\n",
    "# Presentar métricas de desempeño con el mismo formato que en la implementación manual\n",
    "print(\"=== Evaluación con Naïve Bayes de sklearn ===\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de entrenamiento ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_train_spam_sklearn:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_train_ham_sklearn:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_train_promedio_sklearn:.3f}\\n\")\n",
    "\n",
    "print(\"=== Evaluación en conjunto de prueba ===\\n\")\n",
    "print(\"Métricas de evaluación:\")\n",
    "print(f\"- Recall para spam: {recall_test_spam_sklearn:.3f}\")\n",
    "print(f\"- Recall para ham: {recall_test_ham_sklearn:.3f}\")\n",
    "print(f\"- Recall promedio: {recall_test_promedio_sklearn:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál implementación lo hizo mejor? ¿Su implementación o la de la librería?\n",
    "    - Ambas pruebas de recall obtuvieron valores similares\n",
    "        - La implementacion con Sklearn tiene mejor Recall para Spam (+0.007), lo que significa que detecta más mensajes spam correctamente.\n",
    "        - Manual tiene mejor Recall para Ham (+0.001), aunque la diferencia es mínima.\n",
    "        - Sklearn tiene mejor Recall Promedio (+0.003), lo que indica un mejor balance en ambas clases.\n",
    "### ¿Por qué cree que se debe esta diferencia?\n",
    "    - La principal diferencia es que sklearn maneja mejor los cálculos numéricos usando logaritmos en lugar de multiplicaciones, evitando errores de precisión y subdesbordamiento. Además, CountVectorizer preprocesa mejor el texto, eliminando ruido y mejorando la representación del mensaje"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
